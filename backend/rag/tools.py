"""
ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ LangChain Tools ì •ì˜

ì´ íŒŒì¼ì˜ í•¨ìˆ˜ë“¤ì€ @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” íˆ´ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.

** ReAct íŒ¨í„´ì—ì„œì˜ íˆ´ ì—­í•  **
LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , í•„ìš”ì‹œ ììœ¨ì ìœ¼ë¡œ ì´ íˆ´ë“¤ì„ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
ì˜ˆ: "í™ìµëŒ€ ì»´ê³µ ê³¼ëª© ì•Œë ¤ì¤˜" â†’ LLMì´ retrieve_courses íˆ´ í˜¸ì¶œ ê²°ì • â†’ ê³¼ëª© ì •ë³´ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±

** ì œê³µë˜ëŠ” íˆ´ë“¤ **
1. retrieve_courses: ê³¼ëª© ê²€ìƒ‰ (ë©”ì¸ íˆ´, ê°€ì¥ ìì£¼ ì‚¬ìš©ë¨)
2. list_departments: í•™ê³¼ ëª©ë¡ ì¡°íšŒ (ëª©ë¡ë§Œ í•„ìš”í•  ë•Œ)
3. recommend_curriculum: í•™ê¸°ë³„ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œ (ì—¬ëŸ¬ í•™ê¸° ê³„íš)
4. get_search_help: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì‚¬ìš© ê°€ì´ë“œ ì œê³µ
5. get_course_detail: íŠ¹ì • ê³¼ëª© ìƒì„¸ ì •ë³´ (í˜„ì¬ ë¯¸ì‚¬ìš©)

** ì‘ë™ ë°©ì‹ **
1. LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„
2. LLMì´ í•„ìš”í•œ íˆ´ ì„ íƒ ë° íŒŒë¼ë¯¸í„° ê²°ì •
3. íˆ´ ì‹¤í–‰ (ì´ íŒŒì¼ì˜ í•¨ìˆ˜ í˜¸ì¶œ)
4. íˆ´ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬
5. LLMì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
"""

from typing import List, Dict, Any, Optional
from langchain_core.tools import tool
from langchain_core.documents import Document
import numpy as np

from .retriever import retrieve_with_filter
from .entity_extractor import extract_filters, build_chroma_filter
from .vectorstore import load_vectorstore
from .embeddings import get_embeddings


def _get_tool_usage_guide() -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ì œê³µí•  íˆ´ ì‚¬ìš© ê°€ì´ë“œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    return """
ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤:

1. **íŠ¹ì • ê³¼ëª© ê²€ìƒ‰**
   - ì˜ˆì‹œ: "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ê³¼ëª© ì¶”ì²œí•´ì¤˜", "1í•™ë…„ í•„ìˆ˜ ê³¼ëª© ì•Œë ¤ì¤˜"
   - ê²€ìƒ‰ì–´ì— ê³¼ëª©ëª…, í•™ë…„, í•™ê¸°, ëŒ€í•™ëª… ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

2. **í•™ê³¼ ëª©ë¡ ì¡°íšŒ**
   - ì˜ˆì‹œ: "ì–´ë–¤ í•™ê³¼ë“¤ì´ ìˆì–´?", "ì»´í“¨í„° ê´€ë ¨ í•™ê³¼ ì•Œë ¤ì¤˜", "ê³µëŒ€ì—ëŠ” ì–´ë–¤ í•™ê³¼ê°€ ìˆì–´?"
   - ì „ì²´ í•™ê³¼ ëª©ë¡ ë˜ëŠ” í‚¤ì›Œë“œë¡œ í•„í„°ë§ëœ í•™ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

3. **ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œ**
   - ì˜ˆì‹œ: "í™ìµëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ 2í•™ë…„ë¶€í„° 4í•™ë…„ê¹Œì§€ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œí•´ì¤˜"
   - ì˜ˆì‹œ: "ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ìˆëŠ”ë° ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ ì•Œë ¤ì¤˜"
   - í•™ê¸°ë³„ë¡œ ë§ì¶¤ ê³¼ëª©ì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤

ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
"""

# í•™ê³¼ ì„ë² ë”© ìºì‹± í•¨ìˆ˜
_DEPT_EMBEDDINGS_CACHE = None
_DEPT_NAMES_CACHE = None

def _load_department_embeddings():
    global _DEPT_EMBEDDINGS_CACHE, _DEPT_NAMES_CACHE
    if _DEPT_EMBEDDINGS_CACHE is not None:
        return _DEPT_NAMES_CACHE, _DEPT_EMBEDDINGS_CACHE

    vs = load_vectorstore()
    embeddings = get_embeddings()

    collection = vs._collection
    results = collection.get(include=["metadatas"])

    departments = sorted({meta["department"]
                          for meta in results["metadatas"]
                          if meta.get("department")})

    # ğŸ”¹ í•œ ë²ˆì— ë°°ì¹˜ ì„ë² ë”© (OpenAIëŠ” ë‚´ë¶€ì—ì„œ ì•Œì•„ì„œ ë°°ì¹˜ ì²˜ë¦¬)
    dept_vecs = embeddings.embed_documents(departments)

    _DEPT_NAMES_CACHE = departments
    _DEPT_EMBEDDINGS_CACHE = np.array(dept_vecs)
    return _DEPT_NAMES_CACHE, _DEPT_EMBEDDINGS_CACHE

# ===== ì „ê³µ ëŒ€ë¶„ë¥˜/ì„¸ë¶€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ =====
MAIN_CATEGORIES = {
    "ê³µí•™": ["ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥", "ì „ê¸° / ì „ì / ë°˜ë„ì²´", "ê¸°ê³„ / ìë™ì°¨ / ë¡œë´‡",
             "í™”í•™ / í™”ê³µ / ì‹ ì†Œì¬", "ì‚°ì—…ê³µí•™ / ì‹œìŠ¤í…œ / ë°ì´í„°ë¶„ì„", "ê±´ì¶• / í† ëª© / ë„ì‹œ",
             "ì—ë„ˆì§€ / í™˜ê²½ / ì›ìë ¥"],
    "ìì—°ê³¼í•™": ["ìˆ˜í•™ / í†µê³„", "ë¬¼ë¦¬ / ì²œë¬¸", "í™”í•™", "ìƒëª…ê³¼í•™ / ë°”ì´ì˜¤", "ì§€êµ¬ê³¼í•™ / í™˜ê²½"],
    "ì˜ì•½Â·ë³´ê±´": ["ì•½í•™", "ê°„í˜¸", "ë³´ê±´í–‰ì • / ë³´ê±´ì •ì±…"],
    "ê²½ì˜Â·ê²½ì œÂ·íšŒê³„": ["ê²½ì˜(ë§ˆì¼€íŒ…, ì¸ì‚¬, ì „ëµ ë“±)", "ê²½ì œ / ê¸ˆìœµ / ê¸ˆìœµê³µí•™", "íšŒê³„ / ì„¸ë¬´"],
    "ì‚¬íšŒê³¼í•™": ["í–‰ì • / ì •ì±…", "ì •ì¹˜ / ì™¸êµ / êµ­ì œê´€ê³„", "ì‚¬íšŒ / ì‚¬íšŒë³µì§€",
                "ì‹¬ë¦¬ / ìƒë‹´", "ì–¸ë¡  / ë¯¸ë””ì–´ / ê´‘ê³  / PR"],
    "ì¸ë¬¸": ["êµ­ì–´ / ë¬¸í•™", "ì˜ì–´ / ì™¸êµ­ì–´", "ì—­ì‚¬ / ê³ ê³ í•™", "ì² í•™ / ì¸ë¥˜í•™ / ì¢…êµí•™"],
    "êµìœ¡": ["êµìœ¡í•™ / êµê³¼êµìœ¡(êµ­ì˜ìˆ˜ ë“±)", "ìœ ì•„êµìœ¡ / íŠ¹ìˆ˜êµìœ¡"],
    "ì˜ˆì²´ëŠ¥": ["ë¯¸ìˆ  / íšŒí™” / ì¡°ì†Œ", "ë””ìì¸(ì‹œê°, ì‚°ì—…, UX/UI ë“±)",
             "ìŒì•… / ì‘ê³¡ / ì—°ì£¼ / ë³´ì»¬", "ì²´ìœ¡ / ìŠ¤í¬ì¸  / ìš´ë™ì¬í™œ"],
    "ìœµí•©/ì‹ ì‚°ì—…": ["ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ / ë¹…ë°ì´í„°", "ì¸ê³µì§€ëŠ¥ / ë¡œë´‡ / ììœ¨ì£¼í–‰",
                  "ê²Œì„ / ì¸í„°ë™í‹°ë¸Œì½˜í…ì¸ ", "ì˜ìƒ / ì½˜í…ì¸  / ìœ íŠœë¸Œ / ë°©ì†¡",
                  "ìŠ¤íƒ€íŠ¸ì—… / ì°½ì—…"]
}

import re

# list_departments ì¿¼ë¦¬ í™•ì¥ í•¨ìˆ˜
def _expand_category_query(query: str) -> tuple[list[str], str]:
    """
    list_departmentsìš© ì¿¼ë¦¬ í™•ì¥:
    - ëŒ€ë¶„ë¥˜(key)ë¥¼ ë„£ìœ¼ë©´: í•´ë‹¹ keyì— ì†í•œ ëª¨ë“  ì„¸ë¶€ valueë“¤ì„ í’€ì–´ì„œ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
    - ì„¸ë¶€ ë¶„ë¥˜(value)ë¥¼ ë„£ìœ¼ë©´: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" â†’ ["ì»´í“¨í„°","ì†Œí”„íŠ¸ì›¨ì–´","ì¸ê³µì§€ëŠ¥"]
    - ê·¸ ì™¸ ì¼ë°˜ í…ìŠ¤íŠ¸: "/", "," ê¸°ì¤€ìœ¼ë¡œ í† í° ë‚˜ëˆˆ ë’¤ ì‚¬ìš©

    Returns:
        tokens: ["ì»´í“¨í„°", "ì†Œí”„íŠ¸ì›¨ì–´", "ì¸ê³µì§€ëŠ¥", ...]
        embed_text: "ì»´í“¨í„° ì†Œí”„íŠ¸ì›¨ì–´ ì¸ê³µì§€ëŠ¥ ..." (ì„ë² ë”©ì— ë„£ì„ ë¬¸ìì—´)
    """
    raw = query.strip()
    if not raw:
        return [], ""

    tokens: list[str] = []

    # 1) ëŒ€ë¶„ë¥˜(key) ì…ë ¥ì¸ ê²½ìš° â†’ í•´ë‹¹ keyì˜ ëª¨ë“  ì„¸ë¶€ valueë¥¼ í•œêº¼ë²ˆì— í’€ì–´ì„œ ì‚¬ìš©
    if raw in MAIN_CATEGORIES:
        details = MAIN_CATEGORIES[raw]
        for item in details:
            parts = [p.strip() for p in re.split(r"[\/,()]", item) if p.strip()]
            tokens.extend(parts)

    # 2) ì„¸ë¶€ ë¶„ë¥˜(value) ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
    elif any(raw in v for values in MAIN_CATEGORIES.values() for v in values):
        parts = [p.strip() for p in re.split(r"[\/,()]", raw) if p.strip()]
        tokens.extend(parts)

    # 3) ì¼ë°˜ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ (ì˜ˆ: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥", "AI, ë°ì´í„°")
    else:
        parts = [p.strip() for p in re.split(r"[\/,]", raw) if p.strip()]
        if parts:
            tokens.extend(parts)
        else:
            tokens.append(raw)

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    dedup_tokens = []
    for t in tokens:
        if t not in seen:
            seen.add(t)
            dedup_tokens.append(t)

    embed_text = " ".join(dedup_tokens) if dedup_tokens else raw
    return dedup_tokens, embed_text



@tool
def retrieve_courses(
    query: Optional[str] = None,
    university: Optional[str] = None,
    college: Optional[str] = None,
    department: Optional[str] = None,
    grade: Optional[str] = None,
    semester: Optional[str] = None,
    top_k: int = 5
) -> List[Dict[str, Any]]:
    """
    ëŒ€í•™ ê³¼ëª© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ê³¼ëª©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    í•™ê³¼ëª…ì€ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ ìë™ ì •ê·œí™”ë˜ì–´ ìœ ì—°í•œ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.

    ** ì¤‘ìš”: ì´ í•¨ìˆ˜ëŠ” LLMì´ ììœ¨ì ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” Toolì…ë‹ˆë‹¤ **
    ** í•™ìƒì´ íŠ¹ì • ëŒ€í•™, í•™ê³¼, ê³¼ëª©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ë°˜ë“œì‹œ ì´ íˆ´ì„ ë¨¼ì € í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤! **

    ** í•„ìˆ˜ ì‚¬ìš© ìƒí™© **
    - í•™ìƒì´ íŠ¹ì • ëŒ€í•™/í•™ê³¼ë¥¼ ì–¸ê¸‰í•  ë•Œ (ì˜ˆ: "í™ìµëŒ€í•™êµ ì»´í“¨í„°ê³µí•™", "ì„œìš¸ëŒ€ ì „ìê³µí•™ê³¼")
    - í•™ìƒì´ ê³¼ëª© ì¶”ì²œì„ ìš”ì²­í•  ë•Œ (ì˜ˆ: "ì¸ê³µì§€ëŠ¥ ê³¼ëª© ì¶”ì²œí•´ì¤˜", "1í•™ë…„ í•„ìˆ˜ ê³¼ëª©")
    - í•™ìƒì´ íŠ¹ì • ë¶„ì•¼ ê³¼ëª©ì„ ë¬¼ì–´ë³¼ ë•Œ (ì˜ˆ: "ë°ì´í„°ë¶„ì„ ê³¼ëª©", "ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ìˆ˜ì—…")

    ** í˜¸ì¶œ ë°©ë²• **
    1. queryë§Œ ì‚¬ìš©: retrieve_courses(query="í™ìµëŒ€í•™êµ ì»´í“¨í„°ê³µí•™")
    2. íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©: retrieve_courses(university="í™ìµëŒ€í•™êµ", department="ì»´í“¨í„°ê³µí•™")
    3. í˜¼í•© ì‚¬ìš©: retrieve_courses(query="ì¸ê³µì§€ëŠ¥", university="í™ìµëŒ€í•™êµ")

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜µì…˜, ì˜ˆ: "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ê³¼ëª©", "1í•™ë…„ í•„ìˆ˜ ê³¼ëª©")
               queryê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤ë¡œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.
        university: ëŒ€í•™êµ ì´ë¦„ (ì˜µì…˜, ì˜ˆ: "ì„œìš¸ëŒ€í•™êµ", "í™ìµëŒ€í•™êµ")
        college: ë‹¨ê³¼ëŒ€í•™ ì´ë¦„ (ì˜µì…˜, ì˜ˆ: "ê³µê³¼ëŒ€í•™", "ìì—°ê³¼í•™ëŒ€í•™")
        department: í•™ê³¼ ì´ë¦„ (ì˜µì…˜, ì˜ˆ: "ì»´í“¨í„°ê³µí•™", "ì „ìê³µí•™", "ë°”ì´ì˜¤ìœµí•©")
        grade: í•™ë…„ (ì˜µì…˜, ì˜ˆ: "1í•™ë…„", "2í•™ë…„")
        semester: í•™ê¸° (ì˜µì…˜, ì˜ˆ: "1í•™ê¸°", "2í•™ê¸°")
        top_k: ê²€ìƒ‰í•  ê³¼ëª© ìˆ˜ (ê¸°ë³¸ê°’: 5)

    Returns:
        ê³¼ëª© ë¦¬ìŠ¤íŠ¸ [{"id": "...", "name": "...", "university": "...", ...}, ...]
    """
    # queryê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤ë¡œë¶€í„° ìë™ ìƒì„±
    auto_generated = False
    if not query:
        query_parts = []
        if university:
            query_parts.append(university)
        if college:
            query_parts.append(college)
        if department:
            query_parts.append(department)
        if grade:
            query_parts.append(grade)
        if semester:
            query_parts.append(semester)

        if query_parts:
            query = " ".join(query_parts)
            auto_generated = True
        else:
            # ì•„ë¬´ íŒŒë¼ë¯¸í„°ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¿¼ë¦¬
            query = "ì¶”ì²œ ê³¼ëª©"
            auto_generated = True

    if auto_generated:
        print(f"âœ… Using retrieve_courses tool (auto-generated query: '{query}')")
        print(f"   Params: university={university}, college={college}, department={department}, grade={grade}, semester={semester}")
    else:
        print(f"âœ… Using retrieve_courses tool with query: '{query}'")
    # 1. ì¿¼ë¦¬ì—ì„œ í•„í„° ìë™ ì¶”ì¶œ (ì˜ˆ: "ì„œìš¸ëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ 1í•™ë…„" â†’ university, department, grade)
    extracted = extract_filters(query)
    print(f"   Extracted filters: {extracted}")

    # 2. íŒŒë¼ë¯¸í„°ë¡œ ë°›ì€ í•„í„°ì™€ ì¶”ì¶œí•œ í•„í„° ë³‘í•© (íŒŒë¼ë¯¸í„°ê°€ ìš°ì„ )
    filters = extracted.copy() if extracted else {}
    if university:
        filters['university'] = university
    if college:
        filters['college'] = college
    if department:
        filters['department'] = department
    if grade:
        filters['grade'] = grade
    if semester:
        filters['semester'] = semester

    # 3. Chroma DB ì¿¼ë¦¬ í˜•ì‹ìœ¼ë¡œ í•„í„° ìƒì„±
    chroma_filter = build_chroma_filter(filters) if filters else None

    # 4. ë²¡í„° DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    docs: List[Document] = retrieve_with_filter(
        question=query,
        search_k=top_k,
        metadata_filter=chroma_filter
    )

    # 5. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ì˜ˆì™¸ì²˜ë¦¬
    if not docs:
        print(f"âš ï¸  WARNING: No courses found for query='{query}', filters={chroma_filter}")
        return [{
            "error": "no_results",
            "message": "ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.",
            "suggestion": "get_search_help íˆ´ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”."
        }]

    # 6. LangChain Documentë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ Dict í˜•íƒœë¡œ ë³€í™˜
    results = []
    for idx, doc in enumerate(docs):
        meta = doc.metadata
        results.append({
            "id": f"course_{idx}",
            "name": meta.get("name", "[ì´ë¦„ ì—†ìŒ]"),
            "university": meta.get("university", "[ì •ë³´ ì—†ìŒ]"),
            "college": meta.get("college", "[ì •ë³´ ì—†ìŒ]"),
            "department": meta.get("department", "[ì •ë³´ ì—†ìŒ]"),
            "grade_semester": meta.get("grade_semester", "[ì •ë³´ ì—†ìŒ]"),
            "classification": meta.get("course_classification", "[ì •ë³´ ì—†ìŒ]"),
            "description": doc.page_content or "[ëŒ€í•™ ì •ì±…ìƒ ì—´ëŒì´ ì œí•œë©ë‹ˆë‹¤. ìì„¸í•œ ì‚¬í•­ì€ í•™ê³¼ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.]"
        })

    print(f"âœ… Found {len(results)} courses")
    for r in results[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
        print(f"   - {r['name']} ({r['university']} {r['department']})")

    return results


@tool
def get_course_detail(course_id: str, courses_context: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ì´ì „ì— ê²€ìƒ‰ëœ ê³¼ëª© ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ê³¼ëª©ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ** ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ **
    1. LLMì´ ë¨¼ì € retrieve_coursesë¡œ ê³¼ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
    2. í•™ìƒì´ íŠ¹ì • ê³¼ëª©ì— ëŒ€í•´ ë” ìì„¸íˆ ë¬¼ì–´ë´„
    3. LLMì´ ì´ íˆ´ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ê³¼ëª©ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒ

    Args:
        course_id: ê³¼ëª© ID (ì˜ˆ: "course_0", "course_1")
        courses_context: ì´ì „ì— retrieve_coursesë¡œ ê°€ì ¸ì˜¨ ê³¼ëª© ë¦¬ìŠ¤íŠ¸

    Returns:
        ê³¼ëª© ìƒì„¸ ì •ë³´ {"id": "...", "name": "...", "description": "...", ...}
    """
    print(f"âœ… Using get_course_detail tool for course_id: {course_id}")
    # ì£¼ì–´ì§„ course_idì™€ ì¼ì¹˜í•˜ëŠ” ê³¼ëª©ì„ courses_contextì—ì„œ ì°¾ì•„ ë°˜í™˜
    for course in courses_context:
        if course.get("id") == course_id:
            return course

    # í•´ë‹¹ IDê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ID ëª©ë¡ ë°˜í™˜
    return {
        "error": f"ID '{course_id}'ì— í•´ë‹¹í•˜ëŠ” ê³¼ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "available_ids": [c["id"] for c in courses_context]
    }


@tool
def list_departments(query: str, top_k: int = 10) -> List[str]:
    """
    Vector DBì— ìˆëŠ” í•™ê³¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. (í•™ê³¼ëª…ë§Œ ë°˜í™˜, ëŒ€í•™ëª… ì œì™¸)
    ì„ë² ë”© + í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ìœ ì—°í•œ í•™ê³¼ëª… ë§¤ì¹­ì„ ì§€ì›í•©ë‹ˆë‹¤.

    - query = "ì „ì²´" â†’ ëª¨ë“  í•™ê³¼
    - query = "ê³µí•™" â†’ ê³µí•™ ëŒ€ë¶„ë¥˜ ì „ì²´ (ì»´í“¨í„°/ì „ê¸°/ê¸°ê³„/í™”ê³µ/ì‚°ì—…/ê±´ì¶•/ì—ë„ˆì§€ ...)
    - query = "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" â†’ í•´ë‹¹ value ê¸°ë°˜ìœ¼ë¡œ í•™ê³¼ ê²€ìƒ‰
    """
    print(f"âœ… Using list_departments tool with query: '{query}'")

    vs = load_vectorstore()
    collection = vs._collection

    # ì „ì²´ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    results = collection.get(include=['metadatas'])

    departments_set = set()
    all_departments_with_info = []

    for meta in results['metadatas']:
        university = meta.get('university', '')
        college = meta.get('college', '')
        department = meta.get('department', '')

        if department:
            departments_set.add(department)
            all_departments_with_info.append({
                "university": university,
                "college": college,
                "department": department
            })

    # 0. ì „ì²´ ìš”ì²­ì´ë©´ ì „ë¶€ ë°˜í™˜
    if query.strip() == "ì „ì²´" or not query.strip():
        result = sorted(list(departments_set))
        print(f"âœ… Found {len(result)} unique departments (all)")
        return result

    # 1. ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ ì¿¼ë¦¬ í™•ì¥
    tokens, embed_text = _expand_category_query(query)
    if not tokens:
        tokens = [query.strip()]
    query_tokens_lower = [t.lower() for t in tokens]
    print(f"   â„¹ï¸ Expanded query tokens: {query_tokens_lower}")
    print(f"   â„¹ï¸ Embedding text: '{embed_text}'")

    # 2. ë¬¸ìì—´ ê¸°ë°˜ ë§¤ì¹­ - ìœ ì—°í•œ í† í° ë§¤ì¹­ìœ¼ë¡œ ë³€ê²½
    # "ì»´í“¨í„°ê³µí•™"ë„ "ì»´í“¨í„°ê³µí•™ë¶€"ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ê°œì„ 
    matching_departments = {}  # {department_name: match_score}

    for dept_info in all_departments_with_info:
        univ_l = dept_info['university'].lower()
        college_l = dept_info['college'].lower()
        dept_l = dept_info['department'].lower()
        dept_name = dept_info['department']

        # ê° í† í°ì— ëŒ€í•´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        max_score = 0
        for tok in query_tokens_lower:
            # ì™„ì „ ì¼ì¹˜: ìµœê³  ì ìˆ˜
            if tok == dept_l:
                max_score = max(max_score, 3)
            # í•™ê³¼ëª…ì´ í† í°ìœ¼ë¡œ ì‹œì‘: ë†’ì€ ì ìˆ˜ (ì˜ˆ: "ì»´í“¨í„°ê³µí•™"ì´ "ì»´í“¨í„°ê³µí•™ë¶€"ì™€ ë§¤ì¹­)
            elif dept_l.startswith(tok):
                max_score = max(max_score, 2)
            # í† í°ì´ í•™ê³¼ëª…ì— í¬í•¨: ì¤‘ê°„ ì ìˆ˜
            elif tok in dept_l:
                max_score = max(max_score, 1)
            # ëŒ€í•™ëª…ì´ë‚˜ ë‹¨ê³¼ëŒ€í•™ëª…ì— í¬í•¨: ë‚®ì€ ì ìˆ˜
            elif tok in univ_l or tok in college_l:
                max_score = max(max_score, 0.5)

        if max_score > 0:
            # ê¸°ì¡´ í•™ê³¼ê°€ ìˆìœ¼ë©´ ë” ë†’ì€ ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
            if dept_name in matching_departments:
                matching_departments[dept_name] = max(matching_departments[dept_name], max_score)
            else:
                matching_departments[dept_name] = max_score

    print(f"   â„¹ï¸ String match found {len(matching_departments)} departments")

    # 3. ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ (í•­ìƒ ìˆ˜í–‰í•´ì„œ í•˜ì´ë¸Œë¦¬ë“œ í˜•íƒœë¡œ ì‚¬ìš©)
    embedding_candidates: dict[str, float] = {}  # {department_name: similarity_score}
    try:
        embeddings = get_embeddings()
        departments, dept_matrix = _load_department_embeddings()

        # ì¹´í…Œê³ ë¦¬ ì „ì²´ ì˜ë¯¸ë¥¼ ë°˜ì˜í•œ ë¬¸ì¥ì„ ì„ë² ë”©
        query_vec = np.array(embeddings.embed_query(embed_text))

        norms = np.linalg.norm(dept_matrix, axis=1) * np.linalg.norm(query_vec)
        norms = np.where(norms == 0, 1e-10, norms)
        sims = (dept_matrix @ query_vec) / norms

        # threshold ì œê±°í•˜ê³  top_k*2 ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸° (ìœ ì‚¬ í•™ê³¼ë¥¼ ë” ë§ì´ í¬í•¨)
        # ì˜ˆ: "ì»´ê³µ" ê²€ìƒ‰ ì‹œ ì»´í“¨í„°ê³µí•™ê³¼, ì»´í“¨í„°ê³µí•™ë¶€, ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€ ë“± ëª¨ë‘ í¬í•¨
        top_indices = np.argsort(sims)[::-1][:top_k * 2]

        for idx in top_indices:
            dept_name = departments[idx]
            similarity = float(sims[idx])
            embedding_candidates[dept_name] = similarity
            print(f"   - [emb] {dept_name} (similarity: {similarity:.3f})")

    except Exception as e:
        print(f"âš ï¸  Error during embedding search: {e}")

    # 4. ë¬¸ìì—´ + ì„ë² ë”© ê²°ê³¼ í•©ì¹˜ê¸° (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬)
    # ê° í•™ê³¼ì— ëŒ€í•´ ë¬¸ìì—´ ì ìˆ˜ì™€ ì„ë² ë”© ì ìˆ˜ë¥¼ ê²°í•©
    combined_scores = {}

    # ë¬¸ìì—´ ë§¤ì¹­ ì ìˆ˜ ì¶”ê°€ (ì •ê·œí™”: 0~1 ë²”ìœ„ë¡œ ë³€í™˜)
    for dept, score in matching_departments.items():
        combined_scores[dept] = score / 3.0  # ìµœëŒ€ ì ìˆ˜ê°€ 3ì´ë¯€ë¡œ ì •ê·œí™”

    # ì„ë² ë”© ì ìˆ˜ ì¶”ê°€/ì—…ë°ì´íŠ¸ (ì´ë¯¸ 0~1 ë²”ìœ„ì˜ cosine similarity)
    for dept, similarity in embedding_candidates.items():
        if dept in combined_scores:
            # ë‘ ì ìˆ˜ì˜ ê°€ì¤‘ í‰ê·  (ì„ë² ë”© 60%, ë¬¸ìì—´ 40%)
            combined_scores[dept] = 0.6 * similarity + 0.4 * combined_scores[dept]
        else:
            # ì„ë² ë”©ì—ë§Œ ìˆëŠ” ê²½ìš°
            combined_scores[dept] = 0.6 * similarity

    if not combined_scores:
        print("âš ï¸  WARNING: No departments found (string + embedding)")
        return ["ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."]

    # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_departments = sorted(
        combined_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )

    # ìµœì¢… ê²°ê³¼ëŠ” top_k ë§Œí¼ë§Œ ìë¥´ê¸°
    result = [dept for dept, score in sorted_departments[:top_k]]
    print(f"âœ… Returning {len(result)} departments (hybrid string + embedding)")
    for i, (dept, score) in enumerate(sorted_departments[:top_k], 1):
        print(f"   {i}. {dept} (score: {score:.3f})")

    # ğŸ“ êµ¬ì¡°í™”ëœ í¬ë§·ìœ¼ë¡œ ë°˜í™˜ (LLMì´ ë³µì‚¬í•˜ê¸° ì‰½ê²Œ)
    formatted_output = "=" * 80 + "\n"
    formatted_output += f"ğŸ¯ ê²€ìƒ‰ ê²°ê³¼: '{query}'ì— ëŒ€í•œ í•™ê³¼ {len(result)}ê°œ\n"
    formatted_output += "=" * 80 + "\n\n"
    formatted_output += "ğŸ“‹ **ì •í™•í•œ í•™ê³¼ëª… ëª©ë¡** (ì•„ë˜ ë°±í‹± ì•ˆì˜ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”):\n\n"

    for i, dept in enumerate(result, 1):
        formatted_output += f"{i}. `{dept}`\n"

    formatted_output += "\n" + "=" * 80 + "\n"
    formatted_output += "ğŸš¨ **ì¤‘ìš” - ë‹µë³€ ì‘ì„± ê·œì¹™**:\n"
    formatted_output += "   1. ë°±í‹±(`) ì•ˆì˜ í•™ê³¼ëª…ì„ **í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ê³ ** ë³µì‚¬í•˜ì„¸ìš”\n"
    formatted_output += "   2. ìœ„ ëª©ë¡ì— ì—†ëŠ” í•™ê³¼ëª…ì„ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”\n"
    formatted_output += "   3. 'ê³¼', 'ë¶€', 'ì „ê³µ' ë“±ì„ ì¶”ê°€/ì œê±°í•˜ì§€ ë§ˆì„¸ìš”\n\n"
    formatted_output += "   ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:\n"
    formatted_output += "   - ëª©ë¡ì— `ì§€ëŠ¥ë¡œë´‡`ì´ ìˆìœ¼ë©´ â†’ ë‹µë³€: **ì§€ëŠ¥ë¡œë´‡** âœ…\n"
    formatted_output += "   - ëª©ë¡ì— `í™”ê³µí•™ë¶€`ê°€ ìˆìœ¼ë©´ â†’ ë‹µë³€: **í™”ê³µí•™ë¶€** âœ…\n\n"
    formatted_output += "   ì˜ëª»ëœ ì˜ˆì‹œ:\n"
    formatted_output += "   - ëª©ë¡ì— `ì§€ëŠ¥ë¡œë´‡`ì¸ë° â†’ ë‹µë³€: **ì§€ëŠ¥ë¡œë´‡ê³µí•™ê³¼** âŒ (ë‹¨ì–´ ì¶”ê°€)\n"
    formatted_output += "   - ëª©ë¡ì— `í™”ê³µí•™ë¶€`ì¸ë° â†’ ë‹µë³€: **í™”ê³µí•™ê³¼** âŒ (í•™ë¶€â†’í•™ê³¼ ë³€ê²½)\n"
    formatted_output += "=" * 80

    return formatted_output


@tool
def get_universities_by_department(department_name: str) -> List[Dict[str, str]]:
    """
    íŠ¹ì • í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    ** ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ **
    - í•™ìƒì´ íŠ¹ì • í•™ê³¼ë¥¼ ì„ íƒí•œ í›„, í•´ë‹¹ í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ë“¤ì„ ë³´ì—¬ì¤„ ë•Œ ì‚¬ìš©
    - ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼"ë¥¼ ì„ íƒí•˜ë©´ â†’ ì„œìš¸ëŒ€, ì—°ì„¸ëŒ€, ê³ ë ¤ëŒ€ ë“± ëª©ë¡ ì œê³µ

    Args:
        department_name: í•™ê³¼ëª… (ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼", "ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€")

    Returns:
        ëŒ€í•™ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [
            {"university": "ì„œìš¸ëŒ€í•™êµ", "college": "ê³µê³¼ëŒ€í•™", "department": "ì»´í“¨í„°ê³µí•™ê³¼"},
            {"university": "ì—°ì„¸ëŒ€í•™êµ", "college": "ê³µê³¼ëŒ€í•™", "department": "ì»´í“¨í„°ê³µí•™ê³¼"},
            ...
        ]
    """
    print(f"âœ… Using get_universities_by_department tool for: '{department_name}'")

    vs = load_vectorstore()
    collection = vs._collection

    # ëª¨ë“  ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    results = collection.get(include=['metadatas'])

    # í•´ë‹¹ í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì°¾ê¸°
    universities_set = set()
    for meta in results['metadatas']:
        university = meta.get('university', '')
        college = meta.get('college', '')
        department = meta.get('department', '')

        # ì •í™•í•œ ë§¤ì¹­ ë˜ëŠ” ë¶€ë¶„ ë§¤ì¹­
        if department and (department == department_name or department_name in department):
            universities_set.add((university, college, department))

    # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    result = [
        {
            "university": univ,
            "college": college,
            "department": dept
        }
        for univ, college, dept in sorted(universities_set)
    ]

    print(f"âœ… Found {len(result)} universities offering '{department_name}'")

    if not result:
        print(f"âš ï¸  WARNING: No universities found offering '{department_name}'")
        return [{
            "error": "no_results",
            "message": f"'{department_name}' í•™ê³¼ë¥¼ ê°œì„¤í•œ ëŒ€í•™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "suggestion": "í•™ê³¼ëª…ì„ ì •í™•íˆ í™•ì¸í•˜ê±°ë‚˜ list_departmentsë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í•™ê³¼ ëª©ë¡ì„ ë¨¼ì € ì¡°íšŒí•˜ì„¸ìš”."
        }]

    return result


@tool
def recommend_curriculum(
    university: str,
    department: str,
    interests: Optional[str] = None,
    start_grade: int = 2,
    start_semester: int = 1,
    end_grade: int = 4,
    end_semester: int = 2,
    courses_per_semester: int = 5
) -> List[Dict[str, Any]]:
    """
    í•™ìƒì˜ ê´€ì‹¬ì‚¬ë¥¼ ê³ ë ¤í•˜ì—¬ í•™ê¸°ë³„ ë§ì¶¤ ì»¤ë¦¬í˜ëŸ¼ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

    ** ì¤‘ìš”: ì´ í•¨ìˆ˜ëŠ” LLMì´ ììœ¨ì ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” Toolì…ë‹ˆë‹¤ **
    í•™ìƒì´ "2í•™ë…„ë¶€í„° 4í•™ë…„ê¹Œì§€ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œí•´ì¤˜", "ì „ì²´ ì»¤ë¦¬í˜ëŸ¼ ì•Œë ¤ì¤˜" ê°™ì€ ì§ˆë¬¸ì„ í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

    ** ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ **
    1. "í™ìµëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ 2í•™ë…„ë¶€í„° 4í•™ë…„ê¹Œì§€ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œí•´ì¤˜"
       â†’ university="í™ìµëŒ€í•™êµ", department="ì»´í“¨í„°ê³µí•™", start_grade=2, end_grade=4
    2. "ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ìˆëŠ”ë° ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œí•´ì¤˜"
       â†’ interests="ì¸ê³µì§€ëŠ¥"ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ê´€ë ¨ ê³¼ëª© ìš°ì„  ì„ íƒ

    Args:
        university: ëŒ€í•™êµ ì´ë¦„ (ì˜ˆ: "í™ìµëŒ€í•™êµ", "ì„œìš¸ëŒ€í•™êµ")
        department: í•™ê³¼ ì´ë¦„ (ì˜ˆ: "ì»´í“¨í„°ê³µí•™", "ì „ìê³µí•™")
        interests: í•™ìƒì˜ ê´€ì‹¬ ë¶„ì•¼ í‚¤ì›Œë“œ (ì˜ˆ: "ì¸ê³µì§€ëŠ¥", "ë°ì´í„°ë¶„ì„", "ë³´ì•ˆ")
        start_grade: ì‹œì‘ í•™ë…„ (ê¸°ë³¸ê°’: 2)
        start_semester: ì‹œì‘ í•™ê¸° (ê¸°ë³¸ê°’: 1)
        end_grade: ì¢…ë£Œ í•™ë…„ (ê¸°ë³¸ê°’: 4)
        end_semester: ì¢…ë£Œ í•™ê¸° (ê¸°ë³¸ê°’: 2)
        courses_per_semester: í•™ê¸°ë‹¹ ì¶”ì²œ ê³¼ëª© ìˆ˜ (ê¸°ë³¸ê°’: 5)

    Returns:
        í•™ê¸°ë³„ ì¶”ì²œ ê³¼ëª© ë¦¬ìŠ¤íŠ¸ [
            {
                "semester": "2í•™ë…„ 1í•™ê¸°",
                "courses": [
                    {"name": "...", "description": "...", "classification": "..."},
                    {"name": "...", "description": "...", "classification": "..."},
                    ...
                ],
                "count": 5
            },
            ...
        ]
    """
    print(f"âœ… Using recommend_curriculum tool: {university} {department}, interests='{interests}'")

    vs = load_vectorstore()
    embeddings = get_embeddings()

    # ê´€ì‹¬ì‚¬ ì„ë² ë”© ìƒì„± (ìˆëŠ” ê²½ìš°)
    interests_embedding = None
    if interests:
        interests_embedding = embeddings.embed_query(interests)

    curriculum = []
    selected_course_names = set()  # ì¤‘ë³µ ê³¼ëª© ë°©ì§€ìš©

    # í•™ê¸°ë³„ë¡œ ë°˜ë³µ
    for grade in range(start_grade, end_grade + 1):
        for semester in range(1, 3):  # 1í•™ê¸°, 2í•™ê¸°
            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if grade == end_grade and semester > end_semester:
                break
            if grade == start_grade and semester < start_semester:
                continue

            semester_label = f"{grade}í•™ë…„ {semester}í•™ê¸°"

            # í•´ë‹¹ í•™ê¸°ì˜ ê³¼ëª© ê²€ìƒ‰
            filter_dict = {
                'university': university,
                'department': department,
                'grade': f"{grade}í•™ë…„",
                'semester': f"{semester}í•™ê¸°"
            }

            chroma_filter = build_chroma_filter(filter_dict)
            print(f"   [{semester_label}] Searching with filter: {filter_dict}")

            try:
                # í•´ë‹¹ í•™ê¸° ê³¼ëª© ê²€ìƒ‰ (ë” ë§ì€ í›„ë³´ ê°€ì ¸ì˜¤ê¸°)
                docs = retrieve_with_filter(
                    question=interests if interests else "ì¶”ì²œ ê³¼ëª©",
                    search_k=20,  # í•™ê¸°ë‹¹ 5ê°œ ì„ íƒí•˜ë¯€ë¡œ ë” ë§ì€ í›„ë³´ í•„ìš”
                    metadata_filter=chroma_filter
                )

                if not docs:
                    curriculum.append({
                        "semester": semester_label,
                        "courses": [],
                        "count": 0,
                        "message": "í•´ë‹¹ í•™ê¸°ì— ê°œì„¤ëœ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤."
                    })
                    continue

                # ì´ë¯¸ ì„ íƒëœ ê³¼ëª© ì œì™¸
                available_docs = [
                    doc for doc in docs
                    if doc.metadata.get("name", "") not in selected_course_names
                ]

                if not available_docs:
                    print(f"   âš ï¸  [{semester_label}] ëª¨ë“  ê³¼ëª©ì´ ì´ë¯¸ ì„ íƒë¨")
                    curriculum.append({
                        "semester": semester_label,
                        "courses": [],
                        "count": 0,
                        "message": "í•´ë‹¹ í•™ê¸°ì˜ ê³¼ëª©ì´ ì´ë¯¸ ë‹¤ë¥¸ í•™ê¸°ì— ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤."
                    })
                    continue

                # í•™ê¸°ë‹¹ ìµœëŒ€ courses_per_semesterê°œ ê³¼ëª© ì„ íƒ
                selected_courses = []
                for i, doc in enumerate(available_docs[:courses_per_semester]):
                    meta = doc.metadata
                    course_name = meta.get("name", "[ì´ë¦„ ì—†ìŒ]")

                    # ì¤‘ë³µ ì²´í¬
                    if course_name in selected_course_names:
                        continue

                    # ì„ íƒëœ ê³¼ëª© ì¶”ê°€
                    selected_course_names.add(course_name)

                    # ì‹¤ì œ ë©”íƒ€ë°ì´í„° ë¡œê¹… (ë””ë²„ê¹…ìš©)
                    actual_univ = meta.get("university", "[ì •ë³´ ì—†ìŒ]")
                    actual_dept = meta.get("department", "[ì •ë³´ ì—†ìŒ]")
                    actual_grade_sem = meta.get("grade_semester", "[ì •ë³´ ì—†ìŒ]")
                    print(f"   âœ… [{semester_label}] Selected ({i+1}/{courses_per_semester}): {course_name}")
                    print(f"      Source: {actual_univ} / {actual_dept} / {actual_grade_sem}")

                    selected_courses.append({
                        "name": course_name,
                        "classification": meta.get("course_classification", "[ì •ë³´ ì—†ìŒ]"),
                        "description": doc.page_content
                    })

                    # ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ì„ íƒí–ˆìœ¼ë©´ ì¤‘ë‹¨
                    if len(selected_courses) >= courses_per_semester:
                        break

                curriculum.append({
                    "semester": semester_label,
                    "courses": selected_courses,
                    "count": len(selected_courses)
                })

            except Exception as e:
                print(f"Error retrieving courses for {semester_label}: {e}")
                curriculum.append({
                    "semester": semester_label,
                    "courses": [],
                    "count": 0,
                    "message": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                })

    # ì»¤ë¦¬í˜ëŸ¼ ì „ì²´ê°€ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë“  í•­ëª©ì´ ì˜¤ë¥˜ì¸ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬
    valid_items = [item for item in curriculum if item.get("count", 0) > 0]
    if not valid_items:
        print(f"âš ï¸  WARNING: No valid curriculum generated for {university} {department}")
        return [{
            "error": "no_results",
            "message": "ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.",
            "suggestion": "get_search_help íˆ´ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”.",
            "details": f"ëŒ€í•™: {university}, í•™ê³¼: {department}ì— ëŒ€í•œ ì»¤ë¦¬í˜ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }]

    total_courses = sum(item.get("count", 0) for item in curriculum)
    print(f"âœ… Generated curriculum with {len(curriculum)} semesters ({total_courses} total courses)")

    return curriculum




@tool
def match_department_name(department_query: str) -> dict:
    """
    í•™ê³¼ëª…ì„ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ í‘œì¤€ í•™ê³¼ëª…ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.

    ëŒ€í•™ëª…ê³¼ í•™ê³¼ëª…ì´ ì„ì—¬ ìˆëŠ” ê²½ìš° ìë™ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ëŒ€í•™ëª… ì •ê·œí™”ëŠ” univ_mapping.jsonì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Examples:
        'ì»´ê³µ' â†’ 'ì»´í“¨í„°ê³µí•™ê³¼'
        'ì»´í“¨í„°ê³¼' â†’ 'ì»´í“¨í„°ê³µí•™ê³¼'
        'ì†Œí”„íŠ¸ì›¨ì–´' â†’ 'ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€'
        'í™ëŒ€ ì»´ê³µ' â†’ university='í™ìµëŒ€í•™êµ', department='ì»´í“¨í„°ê³µí•™ê³¼'
        'ì„œìš¸ëŒ€ ì „ì „' â†’ university='ì„œìš¸ëŒ€í•™êµ', department='ì „ìê³µí•™ê³¼'
        'ì„¤ëŒ€ ì»´ê³µ' â†’ university='ì„œìš¸ëŒ€í•™êµ', department='ì»´í“¨í„°ê³µí•™ê³¼' (ì€ì–´ ì§€ì›)

    Args:
        department_query: í•™ê³¼ëª… ë˜ëŠ” "ëŒ€í•™ëª… + í•™ê³¼ëª…" í˜•íƒœ (ì˜ˆ: "ì»´ê³µ", "í™ëŒ€ ì»´ê³µ")

    Returns:
        {
            "input": "ì›ë³¸ ì¿¼ë¦¬",
            "university": "ì¶”ì¶œëœ ëŒ€í•™ëª… (ìˆëŠ” ê²½ìš°)",
            "matched_department": "ë§¤ì¹­ëœ í‘œì¤€ í•™ê³¼ëª…",
            "similarity": "ìœ ì‚¬ë„ ì ìˆ˜"
        }
    """
    from backend.rag.entity_extractor import normalize_university_name
    import re

    print(f"âœ… Using match_department_name with query: '{department_query}'")

    # ëŒ€í•™ëª… ì¶”ì¶œ ì‹œë„
    extracted_university = None
    dept_only_query = department_query

    # 1ë‹¨ê³„: ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ëŒ€í•™ëª… ì²´í¬
    tokens = department_query.split()
    if len(tokens) >= 2:
        first_token = tokens[0]

        # entity_extractorì˜ normalize_university_name ì‚¬ìš©
        # ì •ê·œí™” ì‹œë„ (í™ëŒ€ â†’ í™ìµëŒ€í•™êµ, ì„¤ëŒ€ â†’ ì„œìš¸ëŒ€í•™êµ ë“±)
        normalized = normalize_university_name(first_token)

        # ì •ê·œí™”ê°€ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸ (ì›ë³¸ê³¼ ë‹¤ë¥´ë©´ ì„±ê³µ)
        if normalized != first_token or normalized.endswith('ëŒ€í•™êµ'):
            extracted_university = normalized
            # "ëŒ€í•™êµ"ë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
            if not extracted_university.endswith('ëŒ€í•™êµ'):
                extracted_university += 'ëŒ€í•™êµ'

            dept_only_query = ' '.join(tokens[1:])  # ë‚˜ë¨¸ì§€ë¥¼ í•™ê³¼ëª…ìœ¼ë¡œ
            print(f"   Extracted university: {extracted_university} (from '{first_token}')")
            print(f"   Department query: {dept_only_query}")

    # 2ë‹¨ê³„: ê³µë°± ì—†ì´ ë¶™ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ì˜ˆ: "í™ëŒ€ì»´ê³µ")
    # ì •ê·œì‹ìœ¼ë¡œ ëŒ€í•™ëª… íŒ¨í„´ ì°¾ê¸°
    if not extracted_university:
        # "~ëŒ€í•™êµ", "~ëŒ€" íŒ¨í„´ ì°¾ê¸°
        univ_pattern = r'^([ê°€-í£]+ëŒ€í•™êµ|[ê°€-í£]+ëŒ€)'
        univ_match = re.match(univ_pattern, department_query)

        if univ_match:
            univ_token = univ_match.group(1)
            normalized = normalize_university_name(univ_token)

            if normalized != univ_token or normalized.endswith('ëŒ€í•™êµ'):
                extracted_university = normalized
                if not extracted_university.endswith('ëŒ€í•™êµ'):
                    extracted_university += 'ëŒ€í•™êµ'

                # ëŒ€í•™ëª… ë¶€ë¶„ì„ ì œê±°í•œ ë‚˜ë¨¸ì§€ë¥¼ í•™ê³¼ëª…ìœ¼ë¡œ
                dept_only_query = department_query[len(univ_match.group(0)):].strip()
                print(f"   Extracted university: {extracted_university} (from '{univ_token}')")
                print(f"   Department query: {dept_only_query}")

    embeddings = get_embeddings()

    # 1) ìºì‹œëœ í•™ê³¼ëª… + ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    departments, dept_matrix = _load_department_embeddings()

    # 2) í•™ê³¼ëª…ë§Œ ì„ë² ë”©í•˜ì—¬ ë§¤ì¹­
    query_vec = np.array(embeddings.embed_query(dept_only_query))

    # 3) ì „ì²´ í•™ê³¼ì™€ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    norms = np.linalg.norm(dept_matrix, axis=1) * np.linalg.norm(query_vec)
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
    norms = np.where(norms == 0, 1e-10, norms)
    sims = (dept_matrix @ query_vec) / norms

    best_idx = int(np.argmax(sims))
    best_match = departments[best_idx]
    best_score = float(sims[best_idx])

    print(f"   Best match: {best_match} (similarity: {best_score:.3f})")

    result = {
        "input": department_query,
        "matched_department": best_match,
        "similarity": best_score,
    }

    if extracted_university:
        result["university"] = extracted_university

    return result
  
@tool
def get_search_help() -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.
    ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤(ê° íˆ´ì„ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ë²•ë“¤)ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

    ** ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”? **
    1. ë‹¤ë¥¸ íˆ´(retrieve_courses, list_departments, recommend_curriculum)ì˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆì„ ë•Œ
    2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ë¥¼ ìš”ì²­í•  ë•Œ
    3. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì‚¬ìš©ìì—ê²Œ ë‹¤ë¥¸ ê²€ìƒ‰ ë°©ë²•ì„ ì•ˆë‚´í•´ì•¼ í•  ë•Œ

    Returns:
        ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤ì„ ì„¤ëª…í•˜ëŠ” ê°€ì´ë“œ ë©”ì‹œì§€
    """
    print("â„¹ï¸  Using get_search_help tool - providing usage guide to user")
    return _get_tool_usage_guide()
